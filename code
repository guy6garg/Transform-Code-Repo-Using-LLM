{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yuggarg/assignment-msr?scriptVersionId=187280655\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## Assumptions\n1. No submodules in the repo\n2. Since tree sitter parser generates only syntax tree, so during updation only considering syntactic change and not semantic change for a call since for semantic change i.e. contextual change complete code files needs to be inputted and since we are using a comparitively smaller LLM input tokens starts limiting for larger code files.\n3. All original modules are syntactically correct.\n4. Naming conventions are strictly followed across all the files in the repo\n5. For this assignment assuming only python repositories.","metadata":{}},{"cell_type":"markdown","source":"### Functions to parse repo and made a graph structure over it","metadata":{}},{"cell_type":"code","source":"!pip install tree-sitter tree-sitter-python","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-07T21:05:39.784349Z","iopub.execute_input":"2024-07-07T21:05:39.784727Z","iopub.status.idle":"2024-07-07T21:05:52.849147Z","shell.execute_reply.started":"2024-07-07T21:05:39.784697Z","shell.execute_reply":"2024-07-07T21:05:52.847969Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom tree_sitter import Language, Parser\nimport tree_sitter_python as tspython\nimport networkx as nx\nimport matplotlib.pyplot as plt\nfrom pygments import highlight\nfrom pygments.lexers import PythonLexer\nfrom pygments.formatters import TerminalFormatter\n\n# Parser Intializer\nPY_LANGUAGE = Language(tspython.language())\nparser = Parser(PY_LANGUAGE)\n\n# Function to parse file in the repo to get the parser generated syntax tree\ndef parse_file(file_path):\n    '''\n    Parameters: file_path = File path of the code file in repo\n    Return: Parser generated syntax tree\n    '''\n    with open(file_path, 'rb') as file:\n        code = file.read()\n        return parser.parse(code)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T21:05:52.853474Z","iopub.execute_input":"2024-07-07T21:05:52.854238Z","iopub.status.idle":"2024-07-07T21:05:53.215263Z","shell.execute_reply.started":"2024-07-07T21:05:52.854203Z","shell.execute_reply":"2024-07-07T21:05:53.214521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To extract function defined in a file\ndef extract_functions(node, module_name, class_name=None):\n    '''\n    Parameters: node = Root node of the syntax tree for that module\n                class_name = name of the class in the module\n                module_name = Name of the code file\n    Return: A list containing extracted function_name and function node as a tuple\n            where when function is defined in a class it's name is given as {module_name}.{class_name}.{func_name}\n            and as {module_name}.{func_name} in the other case\n    '''\n    functions = []\n    for child in node.children:\n        if child.type == 'function_definition':\n            func_name = child.child_by_field_name('name').text.decode('utf-8')\n            if class_name: # class defined function\n                func_name = f\"{module_name}.{class_name}.{func_name}\"\n            else: # module defined function\n                func_name = f\"{module_name}.{func_name}\"\n            functions.append((func_name, child))\n        elif child.type == 'class_definition':\n            child_class_name = child.child_by_field_name('name').text.decode('utf-8')\n            functions.extend(extract_functions(child.child_by_field_name('body'), module_name, child_class_name))\n    return functions","metadata":{"execution":{"iopub.status.busy":"2024-07-07T21:05:53.216386Z","iopub.execute_input":"2024-07-07T21:05:53.21667Z","iopub.status.idle":"2024-07-07T21:05:53.223884Z","shell.execute_reply.started":"2024-07-07T21:05:53.216646Z","shell.execute_reply":"2024-07-07T21:05:53.222946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to get aliased name from a import statement of either a module, class or function\ndef get_aliased_name(alias_node):\n    '''\n    Parameter: alias_node = Alias Node from import statement\n    Return: module name and alias name\n    '''\n    module_name = None\n    alias_name = None\n    for child in alias_node.children:\n        if child.type == 'aliased_import':\n            module_name = child.child_by_field_name('name').text.decode('utf-8')\n            alias_name = child.child_by_field_name('alias').text.decode('utf-8')\n    return module_name, alias_name\n\n# Function to get all the imported module and their corresponding class and functions in a module\ndef parse_imports(node, imports):\n    '''\n    Parameters: node = Root node of the syntax tree for that module\n                imports = Dictionary to store imported module_name (key) and function and class names (as values)\n                         A class/ function name is stored in their corresponding lists as a tuple (original_name, alias_name)\n    Return: None\n    '''\n    if node.type == 'import_statement':\n        for child in node.children_by_field_name('name'):\n            module_name= child.text.decode('utf-8')\n            module, alias_name = get_aliased_name(child)\n            module_name = module if module else module_name\n            imports[module_name] = {'class':[], 'function':[]}\n            if alias_name:\n                imports[module_name]['as'] = alias_name\n    elif node.type == 'import_from_statement':\n        module_name = node.child_by_field_name('module_name').text.decode('utf-8')\n        imports[module_name] = {'class':[], 'function':[]}\n        for child in node.children_by_field_name('name'):\n            atr_name = child.text.decode('utf-8')\n            atr, alias_name = get_aliased_name(child)\n            atr_name = atr if atr else atr_name\n            if atr_name[0].isupper():\n                imports[module_name]['class'].append((atr_name, alias_name))\n            else:\n                imports[module_name]['function'].append((atr_name, alias_name))\n    for child in node.children:\n        parse_imports(child, imports)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T21:05:53.225946Z","iopub.execute_input":"2024-07-07T21:05:53.226196Z","iopub.status.idle":"2024-07-07T21:05:53.238283Z","shell.execute_reply.started":"2024-07-07T21:05:53.226173Z","shell.execute_reply":"2024-07-07T21:05:53.237395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To check whether the given name is a module imported in the code file\ndef is_module(name, imports):\n    '''\n    Parameters: name = name to check\n                imports = Dictionary which contains imported module_name (key) and function and class names (as values) \n    Return: Tuple (boolean, module_name)\n    '''\n    for module, atr in imports.items():\n        if name == module or ('as' in atr and name == atr['as']):\n            return (True, module)\n    return (False, '')\n\n# To check whether the given name is a class imported in the code file\ndef is_class(name, imports):\n    '''\n    Parameters: name = name to check\n                imports = Dictionary which contains imported module_name (key) and function and class names (as values) \n    Return: List [boolean, class_name, module_name from which it is imported]\n    '''\n    for module_name, atr in imports.items():\n        for class_name in atr['class']:\n            if name in class_name:\n                return [True, class_name[0], module_name]\n    return [False, '', '']\n    \n# To extract class objects intialized in the given module\ndef extract_class_objects(node, module_name, class_objects, imports):\n    '''\n    Parameters: node = Root node of the syntax tree for that module\n                module_name = module name of the code file(name of code file)\n                class_objects = Dictionary to store class objects for that module\n                                where object name is key and value as class name which is in the format {module name where it is defined}.{class name}\n                imports = Dictionary which contains imported module_name and corresponding function/class names \n    Return: None\n    '''\n    for child in node.children:\n        if child.type == 'assignment':\n            left = child.child_by_field_name('left')\n            right = child.child_by_field_name('right')\n            if left and right and right.type == 'call':\n                obj_name = left.text.decode('utf-8')\n                right_name = right.child_by_field_name('function').text.decode('utf-8')\n                class_atr = is_class(right_name, imports) \n                class_name =  f\"{class_atr[2]}.{class_atr[1]}\" if class_atr[1] else ''  # intra module class object if using direct import\n                func_node = right.child_by_field_name('function')\n                if func_node.type == 'attribute': # intra module class object using from import\n                    obj = func_node.child_by_field_name('object').text.decode('utf-8')\n                    func = func_node.child_by_field_name('attribute').text.decode('utf-8')\n                    module = is_module(obj, imports)\n                    class_atr = is_class(func, imports)\n                    if module[0] and class_atr[0] and (module[1] == class_atr[2]):\n                        class_name = f\"{class_atr[2]}.{class_atr[1]}\"\n                elif len(class_name) == 0 and right_name[0].isupper(): # inter module class object \n                    class_name = f\"{module_name}.{right_name}\"\n    \n                if obj_name not in class_objects and class_name:\n                    class_objects[obj_name] = class_name\n        elif child.children:\n            extract_class_objects(child, module_name, class_objects, imports)\n ","metadata":{"execution":{"iopub.status.busy":"2024-07-07T21:05:53.239602Z","iopub.execute_input":"2024-07-07T21:05:53.240095Z","iopub.status.idle":"2024-07-07T21:05:53.252077Z","shell.execute_reply.started":"2024-07-07T21:05:53.240064Z","shell.execute_reply":"2024-07-07T21:05:53.251285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To check whether the given name is a function imported in the code file\ndef is_intra_function(name, imports):\n    '''\n    Parameters: name = name to check\n                imports = Dictionary which contains imported module_name (key) and function and class names (as values) \n    Return: Tuple (boolean, class name in the format {module name where it is defined}.{class name})\n    '''\n    for module_name, atr in imports.items():\n        for func_name in atr['function']:\n            if name in func_name:\n                return (True, f\"{module_name}.{func_name[0]}\")\n    return (False, '')\n\n# To extract function calls from the given module\ndef find_function_calls(node, module_name, function_names, class_objects, imports, calls):\n    '''\n    Parameters: node = Root node of the syntax tree for that module\n                module_name = module name of the code file(name of code file)\n                function_name = Dictionary containing all the defined functions in the repo\n                class_objects = Dictionary containing intialized class object name and class name for the given module\n                imports = Dictionary containing imported module_name and corresponding function/class names \n                calls: Dictionary which would store caller nodes for the defined repo functions\n    Return: None\n    '''\n    if node.type == 'call':\n        func_node = node.child_by_field_name('function')\n        func_name =  func_node.text.decode('utf-8')\n        if func_node.type == 'attribute': # Class function call and Intra function call using module import\n            obj = func_node.child_by_field_name('object').text.decode('utf-8')\n            func = func_node.child_by_field_name('attribute').text.decode('utf-8')\n            full_name = f\"{obj}.{func}\"\n            if obj in class_objects:\n                full_name = f\"{class_objects[obj]}.{func}\"\n            if full_name in function_names:\n                if full_name not in calls:\n                    calls[full_name] = [node]\n                else:\n                    calls[full_name].append(node)\n        elif func_node.type == 'identifier' and not func_name[0].isupper(): # Intra/Inter function call\n            func_atr = is_intra_function(func_name, imports)\n            func_name = func_atr[1] if func_atr[0] else f\"{module_name}.{func_name}\"\n            if func_name in function_names:\n                if func_name not in calls:\n                    calls[func_name] = [node]\n                else:\n                    calls[func_name].append(node)\n    for child in node.children:\n        find_function_calls(child, module_name, function_names, class_objects, imports, calls)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T21:05:53.253139Z","iopub.execute_input":"2024-07-07T21:05:53.253423Z","iopub.status.idle":"2024-07-07T21:05:53.263901Z","shell.execute_reply.started":"2024-07-07T21:05:53.253397Z","shell.execute_reply":"2024-07-07T21:05:53.263028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Graph properties\n1. Two types of nodes i.e. 'function' and 'call'.\n2. For a 'function' node, there would be a edge between its all caller nodes.\n3. Naming convention for a caller node is {module where the call occurred}.{function name in the same convention as described in the above section}_counter where counter is the count of that call for that function","metadata":{}},{"cell_type":"code","source":"# Function to build the graph\ndef build_graph(repo_path):\n    '''\n    Parameters: repo_path = Path of the repo\n    Return: Graph structure of the given repo\n    '''\n    G = nx.DiGraph()\n    functions = {}\n\n    for root, _, files in os.walk(repo_path):\n        for file in files:\n            if file.endswith('.py'):\n                file_path = os.path.join(root, file)\n                module_name = os.path.basename(file_path).replace('.py', '')\n                tree = parse_file(file_path)\n                file_functions = extract_functions(tree.root_node, module_name)\n                \n                for func_name, func_node in file_functions:\n                    if func_name not in functions:\n                        functions[func_name] = func_node\n                        G.add_node(func_name, ast_node=func_node, node_type='function', file_path = file_path)\n     \n    for root, _, files in os.walk(repo_path):\n        for file in files:\n            if file.endswith('.py'):\n                file_path = os.path.join(root, file)\n                module_name = os.path.basename(file_path).replace('.py', '')\n                tree = parse_file(file_path)\n                # Find calls in the entire module\n                class_objects = {}\n                module_calls = {}\n                imports = {}\n                parse_imports(tree.root_node, imports) \n                extract_class_objects(tree.root_node, module_name, class_objects, imports)\n                find_function_calls(tree.root_node, module_name, functions, class_objects, imports, module_calls)\n                # Add edges for function calls\n                module_level_calls = set()\n                \n                for called_func, call_nodes in module_calls.items():\n                    if called_func in functions:\n                        i = 1\n                        for node in call_nodes:\n                            called_func_name = f\"{module_name}.{called_func}_{i}\"\n                            G.add_node(called_func_name, ast_node=node, node_type='call', file_path = file_path)\n                            G.add_edge(called_func, called_func_name, relation = 'call')\n                            i+=1\n                    \n    return G\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T22:43:58.831807Z","iopub.execute_input":"2024-07-07T22:43:58.832736Z","iopub.status.idle":"2024-07-07T22:43:58.845303Z","shell.execute_reply.started":"2024-07-07T22:43:58.8327Z","shell.execute_reply":"2024-07-07T22:43:58.844283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to visualize the graph\ndef visualize_graph(G):\n    '''\n    Parameter: G = graph structure obtained for a repo\n    Return: Outputs the graph on plot\n    '''\n    pos = nx.spring_layout(G)\n    plt.figure(figsize=(20, 15))\n    \n    node_colors = ['lightblue' if G.nodes[node].get('node_type') == 'function' else 'yellow' for node in G.nodes()]\n    \n#     nx.draw(G, pos, with_labels=True, node_color=node_colors, node_size=2000, font_size=8, arrows=True)\n    nx.draw(G, pos, with_labels=True, node_color=node_colors, node_size=2800, font_size=10,arrows=True)\n#     edge_labels = {(u, v): d['relation'] for u, v, d in G.edges(data=True)}\n#     nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n    edge_labels = nx.get_edge_attributes(G, 'relation')\n    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n    plt.title(\"Function Call Graph\")\n    plt.axis('off')\n    plt.show()\n\ndef print_node_info(G):\n    for node in G.nodes:\n        print(f\"Node: {node}\")\n        print(f\"Node Type: {G.nodes[node].get('node_type', 'unknown')}\")\n        if 'ast_node' in G.nodes[node]:\n            ast_node = G.nodes[node]['ast_node']\n            print(\"AST Node Type:\", ast_node.type)\n            print(\"Source Code:\")\n            print(highlight(ast_node.text.decode('utf-8'), PythonLexer(), TerminalFormatter()))\n        else:\n            print(\"(Module node)\")\n        print(\"\\n\" + \"=\"*50 + \"\\n\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T21:05:53.279153Z","iopub.execute_input":"2024-07-07T21:05:53.279569Z","iopub.status.idle":"2024-07-07T21:05:53.290554Z","shell.execute_reply.started":"2024-07-07T21:05:53.279532Z","shell.execute_reply":"2024-07-07T21:05:53.289717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test case to verify the graph structure for a repo","metadata":{}},{"cell_type":"code","source":"def run_tests():\n    test_repo = 'test_repo'\n    os.makedirs(test_repo, exist_ok=True)\n\n    # Main file\n    with open(os.path.join(test_repo, 'main.py'), 'w') as f:\n        f.write('''\nfrom helper import Helper\n\ndef main():\n    helper = Helper()\n    helper.greet(\"Alice\")\n    print_message(\"Hello from main\")\n\ndef print_message(msg):\n    print(msg)\n\nif __name__ == \"__main__\":\n    main()\n''')\n\n    # Helper file\n    with open(os.path.join(test_repo, 'helper.py'), 'w') as f:\n        f.write('''\nclass Helper:\n    def greet(self, name):\n        print(f\"Hello, {name}!\")\n\ndef unused_function():\n    pass\n''')\n\n    graph = build_graph(test_repo)\n    visualize_graph(graph)\n    # Verify graph structure\n    assert 'main.main' in graph.nodes\n    assert 'main.print_message' in graph.nodes\n    assert 'helper.Helper.greet' in graph.nodes\n    assert 'helper.unused_function' in graph.nodes\n    assert graph.has_edge('helper.Helper.greet', 'main.helper.Helper.greet_1')\n    assert graph.has_edge('main.print_message', 'main.main.print_message_1')\n\n    print(\"All tests passed!\")\n    print(\"Please check the below graph for the graph visualization.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T21:05:53.291698Z","iopub.execute_input":"2024-07-07T21:05:53.291991Z","iopub.status.idle":"2024-07-07T21:05:53.301298Z","shell.execute_reply.started":"2024-07-07T21:05:53.291957Z","shell.execute_reply":"2024-07-07T21:05:53.30048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_tests()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T21:05:53.304319Z","iopub.execute_input":"2024-07-07T21:05:53.304643Z","iopub.status.idle":"2024-07-07T21:05:53.84757Z","shell.execute_reply.started":"2024-07-07T21:05:53.304612Z","shell.execute_reply":"2024-07-07T21:05:53.846634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Section to transform the code using LLMs","metadata":{}},{"cell_type":"code","source":"!pip install transformers torch","metadata":{"execution":{"iopub.status.busy":"2024-07-07T21:05:54.429764Z","iopub.execute_input":"2024-07-07T21:05:54.43033Z","iopub.status.idle":"2024-07-07T21:06:06.976084Z","shell.execute_reply.started":"2024-07-07T21:05:54.430298Z","shell.execute_reply":"2024-07-07T21:06:06.974959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Intiailizing the LLM","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\nmodel_name = \"codellama/CodeLlama-7b-Instruct-hf\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")","metadata":{"execution":{"iopub.status.busy":"2024-07-07T21:06:06.977784Z","iopub.execute_input":"2024-07-07T21:06:06.978174Z","iopub.status.idle":"2024-07-07T21:10:46.298373Z","shell.execute_reply.started":"2024-07-07T21:06:06.978136Z","shell.execute_reply":"2024-07-07T21:10:46.297591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Functions to get the modified code files\n","metadata":{}},{"cell_type":"code","source":"import re\n# Function to extract code from the generated text from the LLM\ndef extract_code_from_markdown(markdown_text):\n    '''\n    Parameter: markdown_text = Output text from the LLM \n    Return: Modified code snippet\n    '''\n    code_block_pattern = r'```(.*?)```'\n    matches = re.findall(code_block_pattern, markdown_text, re.DOTALL)\n    # Remove the language identifier if present (e.g., ```python)\n#     code_blocks = [match.split('\\n', 1)[-1] if '\\n' in match else match for match in matches]\n    return matches[1]","metadata":{"execution":{"iopub.status.busy":"2024-07-07T22:51:29.216432Z","iopub.execute_input":"2024-07-07T22:51:29.216941Z","iopub.status.idle":"2024-07-07T22:51:29.222251Z","shell.execute_reply.started":"2024-07-07T22:51:29.216908Z","shell.execute_reply":"2024-07-07T22:51:29.221253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to generate modified function code using LLM\ndef generate_modified_function_code(old_code, modification_instruction):\n    '''\n    Parameter: old_code = Function code to modify extracted from the function graph node\n               modification_instruction = Instruction feeded to the prompt for the modification of code\n    Return: LLM Output Text\n    '''\n    \n    prompt = f\"\"\"\n    The following function which is enclosed within code block needs to be modified based on the instruction provided:\n    ```\n    {old_code}\n    ```\n    Instruction: {modification_instruction}\n    Note: Maintain the code's indentation for the modifed code as the original code.\n    Modified Code:\n    \"\"\"\n     \n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n        \n    outputs = model.generate(\n            **inputs,\n            max_length=512,\n            temperature=0.2,\n            do_sample=True,\n            top_k=50,\n            num_return_sequences=1\n    )\n        \n    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return extract_code_from_markdown(generated_text)\n\n# Function to generate updated call code using OpenAI Codex\ndef generate_updated_call_code(function_name, class_name, original_function, modified_function, original_caller):\n    '''\n    Parameter: function_name = Name of the function which is updated\n               class_name = Name of the class if function is class defined\n               original_function = Original function code\n               modified_function = Updated function code\n               original_caller = Function's caller code which needs to be modified\n    Return: LLM Output Text\n    '''\n    \n    extra_instr = f\"of class {class_name} \" if class_name else ''\n    prompt = f\"\"\"\n    The python function {function_name} {extra_instr}is modified. Both original and modified code are given, compare them syntactically and semantically.\n    Original Function:\n    '''\n    {original_function}\n    '''\n    Modified Function:\n    '''\n    {modified_function}\n    '''\n    Now, after comparing the function if the function is modified update the original caller (which is enclosed within code block) to match the new signature:\n    ```{original_caller}```\n    Modified Caller Code:\n    \"\"\"\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n    outputs = model.generate(\n            **inputs,\n            max_length=512,\n            temperature=0.4,\n            top_k=20,\n            top_p=0.8,\n            do_sample=True,\n            num_return_sequences=1\n    )\n        \n    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return extract_code_from_markdown(generated_text)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T22:09:18.407628Z","iopub.execute_input":"2024-07-07T22:09:18.408515Z","iopub.status.idle":"2024-07-07T22:09:18.418204Z","shell.execute_reply.started":"2024-07-07T22:09:18.408478Z","shell.execute_reply":"2024-07-07T22:09:18.41729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to modify function and calls in the code base\ndef modify_function_and_calls(graph, module_name, class_name, function_name, modification_instruction):\n    '''\n    Parameter: graph = graph structure obtained for a repo\n               module_name = Name of the module where function is defined\n               class_name = Name of the class if function is class defined\n               function_name = Name of the function which needs to be updated\n               modification_instruction = Instruction feeded to the function update prompt for the modification of code\n    Return: A dictionary containing all the modified code files with the original file paths, original function code, updated function code\n    '''\n    \n    if class_name:\n        function_name = f\"{module_name}.{class_name}.{function_name}\"\n    else:\n        function_name = f\"{module_name}.{function_name}\"\n    function_graph_nodes = [node for node, attr in graph.nodes(data=True) if attr['node_type'] == 'function']\n    if function_name not in function_graph_nodes:\n        print(f\"ERROR {function_name} not present in any file in the repository\")\n        return {}\n    \n    fun_graph_node = graph.nodes[function_name]\n    function_node = fun_graph_node['ast_node']\n    file_path = fun_graph_node['file_path']\n    with open(file_path,'r') as f:\n        source_code = f.read()\n    modified_code_files = {}\n    # Modify the function definition\n    start_byte = function_node.start_byte\n    end_byte = function_node.end_byte\n    old_code = function_node.text.decode('utf-8')\n    new_code = generate_modified_function_code(old_code, modification_instruction)\n    \n    # Modify the function calls\n    for caller in list(graph.neighbors(function_name)):\n        call_graph_node = graph.nodes[caller]\n        call_node = call_graph_node['ast_node']\n        caller_file_path = call_graph_node['file_path']\n        if caller_file_path not in modified_code_files:\n            with open(caller_file_path,'r') as f:\n                code = f.read()\n            modified_code_files[caller_file_path] = code\n        caller_source_code = modified_code_files[caller_file_path]\n        start_byte = call_node.start_byte\n        end_byte = call_node.end_byte\n        old_call = call_node.text.decode('utf-8')\n        new_call = generate_updated_call_code(function_name, class_name, old_code, new_code, old_call)\n        caller_source_code = caller_source_code.replace(old_call, new_call, 1)\n        modified_code_files[caller_file_path] = caller_source_code\n    modified_code_files[file_path] = source_code.replace(old_code, new_code, 1)\n    return {'modified_code_files':modified_code_files, 'original_func_code': old_code,'updated_func_code': new_code}\n ","metadata":{"execution":{"iopub.status.busy":"2024-07-07T21:10:46.31961Z","iopub.execute_input":"2024-07-07T21:10:46.320135Z","iopub.status.idle":"2024-07-07T21:10:46.33225Z","shell.execute_reply.started":"2024-07-07T21:10:46.320109Z","shell.execute_reply":"2024-07-07T21:10:46.331408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Functions needed for transformation analysis","metadata":{}},{"cell_type":"code","source":"# To extract the parameter info for a given parameter node\ndef extract_param_info(param_node):\n    '''\n    Parameter: param_node: Tree child parameter node\n    Return: Parameter Name\n    '''\n    param_name = None\n    default_value = None\n    if param_node.type == 'identifier':\n        param_name = param_node.text.decode('utf8')\n    elif param_node.type in ['default_parameter', 'typed_default_parameter']:\n        param_name = param_node.child_by_field_name('name').text.decode('utf8')\n        default_value = param_node.child_by_field_name('value').text.decode('utf8')\n    elif param_node == 'typed_parameter':\n        for child in param_node.children:\n            if child.type == 'identifier':\n                param_name = param_node.text.decode('utf8')\n            \n    return param_name\n\n# To extract the all the input parameters for a function\ndef find_function_params(func_node):\n    '''\n    Parameter: func_node = Tree function node \n    Return: List of all input function parameter name\n    '''\n    if func_node.type == 'function_definition':\n        params = func_node.child_by_field_name('parameters')\n        if params:\n            return [extract_param_info(param) for param in params.children \n                    if param.type in ('identifier', 'default_parameter', 'typed_parameter', 'typed_default_parameter')]\n    \n    return []","metadata":{"execution":{"iopub.status.busy":"2024-07-07T21:10:46.333477Z","iopub.execute_input":"2024-07-07T21:10:46.333741Z","iopub.status.idle":"2024-07-07T21:10:46.343889Z","shell.execute_reply.started":"2024-07-07T21:10:46.333718Z","shell.execute_reply":"2024-07-07T21:10:46.343133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation Function\nNote: Along with these evaluation metrics, human evaluation is done which I believe is the most accurate metric for code generation ","metadata":{}},{"cell_type":"code","source":"import ast\n# To check the transformed code for any compilation error\ndef static_analysis(transformed: str):\n    '''\n    Parameter: transformed = updated code for a file\n    Checks whether the code can be compiled successfully.\n    '''\n    try:\n        ast.parse(transformed)\n        print(\"Transformed code is syntactically correct!\")\n    except SyntaxError as e:\n        f\"Syntax error: {str(e)}\"\n\n\ndef dynamic_analysis(original:str, transformed: str):\n    '''\n    Parameter: original = original code for the file\n               transformed = updated code for the file\n    Return: Dictionary containing similarity ratio and line count difference between original and transformed code\n    Checks similarity ratio and line count difference\n    '''\n    original_lines = original.split('\\n')\n    transformed_lines = transformed.split('\\n')\n\n    # Calculate similarity ratio\n    similarity_ratio = len(set(original_lines) & set(transformed_lines)) / len(set(original_lines) | set(transformed_lines))\n\n    # Calculate line count difference\n    line_count_diff = abs(len(original_lines) - len(transformed_lines))\n\n    return {\n        'similarity_ratio': similarity_ratio,\n        'line_count_diff': line_count_diff\n    }","metadata":{"execution":{"iopub.status.busy":"2024-07-07T21:28:27.855498Z","iopub.execute_input":"2024-07-07T21:28:27.856171Z","iopub.status.idle":"2024-07-07T21:28:27.863227Z","shell.execute_reply.started":"2024-07-07T21:28:27.856138Z","shell.execute_reply":"2024-07-07T21:28:27.862409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to run all the tests for a transformed repo\ndef transformation_run_tests(output_dict):\n    '''\n    Parameter: output_dict = Output dictionary from the modify_function_and_calls function\n    '''\n    modified_code_files = output_dict['modified_code_files']\n    # Printing updated files before testing\n    print(\"\\n\" + \"Updated Files\")\n    for file_path, updated_content in modified_code_files.items():\n        print(f\"Updated Code for {file_path}\")\n        print(updated_content)\n    \n    #Test code transformation\n    print(\"\\n\" + \"Testing code transformation\")\n    try:\n        assert len(modified_code_files) == 2\n        assert os.path.join(test_dir,'logger.py') in modified_code_files\n        assert os.path.join(test_dir,'main.py') in modified_code_files\n\n        # Check if the function signature was updated\n        assert \"def log(self, message: str, log_level: str = 'INFO'):\" in modified_code_files[os.path.join(test_dir,'logger.py')]\n\n        # Check if the function call was updated\n        original_func_node = parser.parse(output_dict['original_func_code'].encode('utf-8'))\n        updated_func_node = parser.parse(output_dict['updated_func_code'].encode('utf-8'))\n        func_param = find_function_params(original_func_node)\n        updated_param = find_function_params(updated_func_node)\n        assert len(func_param) < len(updated_param)\n        assert 'log_level' in updated_param\n        print(\"Files are accurately transformed\")\n    except Exception as e:\n        f\"Error: {str(e)}\"\n    \n    # Static Analysis and Dynamic Analysis\n    print(\"\\n\" + \"STATIC ANALYSIS\")\n    for file_path, updated_content in modified_code_files.items():\n        print(f\"Analysis for {file_path}\")\n        static_analysis(updated_content)\n    \n    # Dynamic Analysis\n    print(\"\\n\" + \"DYNAMIC ANALYSIS\")\n    for file_path, updated_content in modified_code_files.items():\n        print(f\"Analysis for {file_path}\")\n        with open(file_path, 'r') as file:\n            original_content = file.read()\n\n        results = dynamic_analysis(original_content, updated_content)\n        print(f\"Similarity Ratio: {results['similarity_ratio']}\")\n        print(f\"Line Count Difference: {results['line_count_diff']}\")\n    \n    print(\"ALL TESTS PERFORMED\")\n    ","metadata":{"execution":{"iopub.status.busy":"2024-07-07T23:10:52.95662Z","iopub.execute_input":"2024-07-07T23:10:52.95737Z","iopub.status.idle":"2024-07-07T23:10:52.968469Z","shell.execute_reply.started":"2024-07-07T23:10:52.957323Z","shell.execute_reply":"2024-07-07T23:10:52.967322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test cases to check the transformation","metadata":{}},{"cell_type":"code","source":"def transform_test_case():\n    test_dir = 'test_dir'\n    os.makedirs(test_dir, exist_ok=True)\n    # Create sample files\n    with open(os.path.join(test_dir, 'logger.py'), 'w') as f:\n        f.write(\"\"\"\nclass Logger:\n    def log(self, message: str):\n        print(f\"Log: {message}\")\n            \"\"\")\n            \n    with open(os.path.join(test_dir, 'main.py'), 'w') as f:\n        f.write(\"\"\"\nfrom logger import Logger\n\nlogger = Logger()\nlogger.log(\"Hello, world!\")\n            \"\"\")\n    \n    graph = build_graph(test_dir)\n    print(\"Visualizing Repo Graph:\")\n    visualize_graph(graph)\n    \n    module_name = \"logger\"\n    class_name = \"Logger\"\n    function_name = \"log\"\n    new_signature = \"def log(self, message: str, log_level: str = 'INFO'):\"\n    modification_instruction = f\"Add a new parameter `log_level` of type 'str' in the function 'log' and update the function body accordingly to adjust the new parameter. The function new signature should look like '{new_signature}'.\"\n    output_dict = modify_function_and_calls(graph, module_name, class_name, function_name, modification_instruction)\n    if output_dict:\n        transformation_run_tests(output_dict)\n\ntransform_test_case()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T22:13:51.147471Z","iopub.execute_input":"2024-07-07T22:13:51.148126Z","iopub.status.idle":"2024-07-07T22:14:30.703618Z","shell.execute_reply.started":"2024-07-07T22:13:51.148094Z","shell.execute_reply":"2024-07-07T22:14:30.702659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Another test case","metadata":{}},{"cell_type":"code","source":"# Usage\nrepo_path = 'test_repo'\nos.makedirs(repo_path, exist_ok=True)\n\n# Main file\nwith open(os.path.join(repo_path, 'main.py'), 'w') as f:\n    f.write('''\nfrom helper import Helper, unused_function\n\ndef main():\n    helper = Helper()\n    company = \"Apple\"\n    helper.greet(\"Alice\", 50)\n    unused_function(company)\n    print_message(\"Hello from main\")\n\ndef print_message(msg):\n    print(msg)\n\nif __name__ == \"__main__\":\n    main()\n''')\n\n# Helper file\nwith open(os.path.join(repo_path, 'helper.py'), 'w') as f:\n    f.write('''\nclass Helper:\n    def greet(self, name:str, age:int):\n        print(f\"Hello, {name}! You are {age} years old.\")\n\ndef greet_company(company, age):\n    helper = Helper()\n    helper.greet(name, age)\n\n''')\n\n# Logger File\nwith open(os.path.join(repo_path, 'logger.py'), 'w') as f:\n    f.write('''\nimport numpy as np\nclass Logger():\n    def log(self, message:str):\n        print(message)\nlogger = Logger()\nprint(\"Hello, world!\")\ndef greet(name: str, age=18, gender):\n    a = [logger.log(name) for i in range(age) if gender == 'F']\n    np.array(a)\n    return \"Hello, world!\"\ngreet(gender = 'F')\n''')\n\ngraph = build_graph(repo_path)\nprint(\"Visualizing Repo Graph\")\nvisualize_graph(graph)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T22:01:15.076Z","iopub.execute_input":"2024-07-07T22:01:15.076294Z","iopub.status.idle":"2024-07-07T22:01:15.666584Z","shell.execute_reply.started":"2024-07-07T22:01:15.076267Z","shell.execute_reply":"2024-07-07T22:01:15.665406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"module_name = 'helper'\nclass_name = 'Helper'\nfunction_name = 'greet'\nmodification_instruction = \"Remove the parameter `age` from the function 'greet' and update the code accordingly to adjust the change. The function new signature should look like 'greet(name:str)'.\"\noutput_dict = modify_function_and_calls(graph, module_name, class_name, function_name, modification_instruction)\ntransformation_run_tests(output_dict)\n# for file_name, code in modified_code_files.items():\n#     with open(os.path.join(base_path, file_name), 'wb') as f:\n#         f.write(code)\n\nprint(\"Function and calls have been modified successfully.\")","metadata":{"execution":{"iopub.status.busy":"2024-07-07T22:09:26.331567Z","iopub.execute_input":"2024-07-07T22:09:26.332189Z","iopub.status.idle":"2024-07-07T22:10:29.19095Z","shell.execute_reply.started":"2024-07-07T22:09:26.332157Z","shell.execute_reply":"2024-07-07T22:10:29.189966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Insights:\n1. For the two test cases, first test case was transformed accurately but in the second one of the function's caller was not transformed. \n2. Similarity ratio metric could be very useful for those files which have larger code because it could show if the transformed files are not drastically changes. This can also be observed in the test cases since the similarity ratio for that file where the function was defined drastically changed.\n3. Line count difference can support the similarity ratio metric.\n4. Static Analysis which is done to check for any compilation error and in both the cases code was syntactically correct.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}